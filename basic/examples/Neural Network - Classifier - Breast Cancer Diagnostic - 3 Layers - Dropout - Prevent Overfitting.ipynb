{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfb777c3",
   "metadata": {},
   "source": [
    "### Dataset info\n",
    "https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic)\n",
    "\n",
    "The analysis will contemplate the prediction of a certain cancer, indicating whether it is benign (0) or malignant (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6148957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39aa7b23",
   "metadata": {},
   "source": [
    "### Installing required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cd9a041",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/es/.local/lib/python3.8/site-packages (1.4.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/es/.local/lib/python3.8/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in /home/es/.local/lib/python3.8/site-packages (from pandas) (1.22.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/es/.local/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: numpy in /home/es/.local/lib/python3.8/site-packages (1.22.4)\n",
      "Requirement already satisfied: tensorflow in /home/es/.local/lib/python3.8/site-packages (2.11.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/es/.local/lib/python3.8/site-packages (from tensorflow) (15.0.6.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/es/.local/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /home/es/.local/lib/python3.8/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/es/.local/lib/python3.8/site-packages (from tensorflow) (4.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /home/es/.local/lib/python3.8/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/es/.local/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/es/.local/lib/python3.8/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /home/es/.local/lib/python3.8/site-packages (from tensorflow) (2.11.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/es/.local/lib/python3.8/site-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: packaging in /home/es/.local/lib/python3.8/site-packages (from tensorflow) (22.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/es/.local/lib/python3.8/site-packages (from tensorflow) (1.51.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (45.2.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/es/.local/lib/python3.8/site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/es/.local/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/es/.local/lib/python3.8/site-packages (from tensorflow) (23.1.4)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/es/.local/lib/python3.8/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1; platform_machine != \"arm64\" or platform_system != \"Darwin\" in /home/es/.local/lib/python3.8/site-packages (from tensorflow) (0.29.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/es/.local/lib/python3.8/site-packages (from tensorflow) (1.22.4)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/es/.local/lib/python3.8/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/es/.local/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/es/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/es/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/es/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/es/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/es/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.34.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/es/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/es/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/es/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/es/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.2.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/es/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/es/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/es/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (4.11.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/es/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/es/.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/es/.local/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: keras in /home/es/.local/lib/python3.8/site-packages (2.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ccc332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "175e7fb4",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae46fb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a73902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48a93b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('datasets/breast_cancer_wisconsin_diagnostic_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89fa47c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = pd.read_csv('datasets/breast_cancer_wisconsin_diagnostic_classes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fece868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9dac128",
   "metadata": {},
   "source": [
    "### Building the Neural Network with Dropout\n",
    "\n",
    "The use of Dropout helps to prevent the occurrence of Overfitting, as it resets some neurons based on a specified percentage, giving the model greater variability in predictions.\n",
    "\n",
    "Dropout: https://keras.io/api/layers/regularization_layers/dropout/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "884314f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-21 18:59:40.524188: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-21 18:59:41.980738: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-21 18:59:41.981017: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-21 18:59:46.418518: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-21 18:59:46.418947: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-21 18:59:46.418978: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fd1ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "888a3afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    features = data.shape[1]\n",
    "    output = 1\n",
    "    units = math.ceil((features + output) / 2)\n",
    "    \n",
    "    adam_optimizer = keras.optimizers.Adam(learning_rate=0.001, decay=0.0001, clipvalue=0.5)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=units, activation='relu', kernel_initializer='random_uniform', input_dim=features))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=units, activation='relu', kernel_initializer='random_uniform'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=output, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer=adam_optimizer, loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60576783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6675d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "824d4b0a",
   "metadata": {},
   "source": [
    "### Applying Cross Validation\n",
    "\n",
    "The value most used by the scientific community for folds is 10.\n",
    "\n",
    "A very high value does not make sense, as this can make the execution unfeasible.\n",
    "\n",
    "The cv parameter of cross_val_scoe refers to cross validation, which indicates the number of iterations that will be performed on the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c9d91ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a259c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "478eafe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_148773/3961096699.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  classifier = KerasClassifier(build_fn=build_model, epochs=100, batch_size=10)\n"
     ]
    }
   ],
   "source": [
    "classifier = KerasClassifier(build_fn=build_model, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d90822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a489bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-21 18:59:56.317030: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-21 18:59:56.319309: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-21 18:59:56.319810: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-21 18:59:56.319942: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-21 18:59:56.320011: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-01-21 18:59:56.320080: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-01-21 18:59:56.320157: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-21 18:59:56.320214: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-21 18:59:56.320271: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-01-21 18:59:56.320285: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-01-21 18:59:56.346127: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "52/52 [==============================] - 6s 34ms/step - loss: 1.4515 - binary_accuracy: 0.5566\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.6287 - binary_accuracy: 0.6289\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.5746 - binary_accuracy: 0.6895\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.5744 - binary_accuracy: 0.6797\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 0.6084 - binary_accuracy: 0.7402\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 0.5124 - binary_accuracy: 0.7578\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 0.6790 - binary_accuracy: 0.7773\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5821 - binary_accuracy: 0.7891\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 1s 9ms/step - loss: 0.6019 - binary_accuracy: 0.7969\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 0.5836 - binary_accuracy: 0.7930\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.5685 - binary_accuracy: 0.7930\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.5462 - binary_accuracy: 0.7988\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.4675 - binary_accuracy: 0.8301\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 0.5612 - binary_accuracy: 0.8262\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 0.5195 - binary_accuracy: 0.8477\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.5495 - binary_accuracy: 0.8145\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4160 - binary_accuracy: 0.8535\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5131 - binary_accuracy: 0.8516\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.5249 - binary_accuracy: 0.8535\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5774 - binary_accuracy: 0.8496\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.5142 - binary_accuracy: 0.8535\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.5801 - binary_accuracy: 0.8613\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.5623 - binary_accuracy: 0.8613\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.6630 - binary_accuracy: 0.8672\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 0.4111 - binary_accuracy: 0.8711\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.5183 - binary_accuracy: 0.8613\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 0.4973 - binary_accuracy: 0.8594\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.5017 - binary_accuracy: 0.8633\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5024 - binary_accuracy: 0.8555\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 0.6801 - binary_accuracy: 0.8789\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 2s 38ms/step - loss: 0.5619 - binary_accuracy: 0.8750\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 0.6339 - binary_accuracy: 0.8594\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.6359 - binary_accuracy: 0.8496\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.5474 - binary_accuracy: 0.8848\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.7532 - binary_accuracy: 0.8535\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.4430 - binary_accuracy: 0.8750\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 0.4946 - binary_accuracy: 0.8574\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.4198 - binary_accuracy: 0.8594\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.6457 - binary_accuracy: 0.8711\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 0.7483 - binary_accuracy: 0.8789\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.6119 - binary_accuracy: 0.8867\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.6148 - binary_accuracy: 0.8945\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 0.4946 - binary_accuracy: 0.8789\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.4688 - binary_accuracy: 0.8789\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.9901 - binary_accuracy: 0.8809\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7431 - binary_accuracy: 0.8652\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4280 - binary_accuracy: 0.8730\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6666 - binary_accuracy: 0.8926\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6268 - binary_accuracy: 0.8730\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.0434 - binary_accuracy: 0.8848\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9746 - binary_accuracy: 0.8926\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8152 - binary_accuracy: 0.8926\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5492 - binary_accuracy: 0.8906\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8546 - binary_accuracy: 0.8906\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9535 - binary_accuracy: 0.8906\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4357 - binary_accuracy: 0.8770\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3612 - binary_accuracy: 0.8984\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.0777 - binary_accuracy: 0.8789\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4189 - binary_accuracy: 0.8848\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6205 - binary_accuracy: 0.8984\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.6978 - binary_accuracy: 0.8965\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5872 - binary_accuracy: 0.8926\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7465 - binary_accuracy: 0.8867\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.6760 - binary_accuracy: 0.8809\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4898 - binary_accuracy: 0.9043\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.1318 - binary_accuracy: 0.8887\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.0487 - binary_accuracy: 0.8789\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8374 - binary_accuracy: 0.8945\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6091 - binary_accuracy: 0.8926\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.7267 - binary_accuracy: 0.8945\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.1275 - binary_accuracy: 0.8828\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6110 - binary_accuracy: 0.8887\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6010 - binary_accuracy: 0.8887\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.1462 - binary_accuracy: 0.8906\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.7916 - binary_accuracy: 0.8809\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6670 - binary_accuracy: 0.8867\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 1.1448 - binary_accuracy: 0.8945\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4328 - binary_accuracy: 0.9043\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.0367 - binary_accuracy: 0.8926\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5906 - binary_accuracy: 0.9082\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7076 - binary_accuracy: 0.9023\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.2808 - binary_accuracy: 0.9082\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5909 - binary_accuracy: 0.8945\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8996 - binary_accuracy: 0.8945\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4145 - binary_accuracy: 0.8984\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.0017 - binary_accuracy: 0.8984\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3588 - binary_accuracy: 0.8965\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.3500 - binary_accuracy: 0.8750\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6863 - binary_accuracy: 0.8848\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0928 - binary_accuracy: 0.8730\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7321 - binary_accuracy: 0.8828\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5788 - binary_accuracy: 0.9004\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9953 - binary_accuracy: 0.9160\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8674 - binary_accuracy: 0.9102\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8965 - binary_accuracy: 0.8828\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3094 - binary_accuracy: 0.9199\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4389 - binary_accuracy: 0.8984\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8487 - binary_accuracy: 0.9082\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.2189 - binary_accuracy: 0.8789\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.5596 - binary_accuracy: 0.8867\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 1s 3ms/step - loss: 1.6486 - binary_accuracy: 0.5664\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.7362 - binary_accuracy: 0.6152\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6299 - binary_accuracy: 0.6504\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5628 - binary_accuracy: 0.6738\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5999 - binary_accuracy: 0.6816\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5883 - binary_accuracy: 0.7227\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7462 - binary_accuracy: 0.6855\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5899 - binary_accuracy: 0.7305\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6084 - binary_accuracy: 0.7285\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5878 - binary_accuracy: 0.7383\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5283 - binary_accuracy: 0.7598\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5411 - binary_accuracy: 0.7754\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5366 - binary_accuracy: 0.7598\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5877 - binary_accuracy: 0.7383\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5030 - binary_accuracy: 0.7832\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5081 - binary_accuracy: 0.7773\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4995 - binary_accuracy: 0.7773\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5744 - binary_accuracy: 0.7402\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4868 - binary_accuracy: 0.7910\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4907 - binary_accuracy: 0.7773\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4727 - binary_accuracy: 0.7910\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4965 - binary_accuracy: 0.7852\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4741 - binary_accuracy: 0.7812\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4555 - binary_accuracy: 0.7734\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4215 - binary_accuracy: 0.8047\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4290 - binary_accuracy: 0.7988\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4578 - binary_accuracy: 0.8086\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4604 - binary_accuracy: 0.8047\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4496 - binary_accuracy: 0.8262\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4755 - binary_accuracy: 0.8008\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4483 - binary_accuracy: 0.8047\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4579 - binary_accuracy: 0.8379\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4379 - binary_accuracy: 0.8223\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4365 - binary_accuracy: 0.8359\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4440 - binary_accuracy: 0.7988\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4509 - binary_accuracy: 0.8340\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4522 - binary_accuracy: 0.8203\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4548 - binary_accuracy: 0.8203\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4493 - binary_accuracy: 0.8301\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4166 - binary_accuracy: 0.8262\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4100 - binary_accuracy: 0.8477\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3869 - binary_accuracy: 0.8594\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3894 - binary_accuracy: 0.8398\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4967 - binary_accuracy: 0.8223\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3774 - binary_accuracy: 0.8379\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4395 - binary_accuracy: 0.8438\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4247 - binary_accuracy: 0.8359\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3940 - binary_accuracy: 0.8594\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4301 - binary_accuracy: 0.8242\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4234 - binary_accuracy: 0.8438\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3977 - binary_accuracy: 0.8379\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4259 - binary_accuracy: 0.8438\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3929 - binary_accuracy: 0.8359\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5033 - binary_accuracy: 0.8418\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3536 - binary_accuracy: 0.8613\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4407 - binary_accuracy: 0.8457\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3926 - binary_accuracy: 0.8691\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3781 - binary_accuracy: 0.8633\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3924 - binary_accuracy: 0.8594\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3698 - binary_accuracy: 0.8652\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3843 - binary_accuracy: 0.8613\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3634 - binary_accuracy: 0.8633\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3446 - binary_accuracy: 0.8730\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4516 - binary_accuracy: 0.8379\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4198 - binary_accuracy: 0.8594\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3394 - binary_accuracy: 0.8730\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3818 - binary_accuracy: 0.8613\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3661 - binary_accuracy: 0.8613\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4047 - binary_accuracy: 0.8750\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4491 - binary_accuracy: 0.8574\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3643 - binary_accuracy: 0.8750\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3321 - binary_accuracy: 0.8789\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4352 - binary_accuracy: 0.8477\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4556 - binary_accuracy: 0.8770\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3405 - binary_accuracy: 0.8691\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4979 - binary_accuracy: 0.8379\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4652 - binary_accuracy: 0.8594\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4892 - binary_accuracy: 0.8594\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4124 - binary_accuracy: 0.8613\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4999 - binary_accuracy: 0.8613\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4190 - binary_accuracy: 0.8574\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4521 - binary_accuracy: 0.8535\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4759 - binary_accuracy: 0.8555\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4017 - binary_accuracy: 0.8789\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4212 - binary_accuracy: 0.8594\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4560 - binary_accuracy: 0.8594\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3618 - binary_accuracy: 0.8789\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4191 - binary_accuracy: 0.8652\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3929 - binary_accuracy: 0.8613\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5835 - binary_accuracy: 0.8672\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6932 - binary_accuracy: 0.8691\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4883 - binary_accuracy: 0.8418\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3499 - binary_accuracy: 0.8867\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4635 - binary_accuracy: 0.8613\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7175 - binary_accuracy: 0.8594\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4345 - binary_accuracy: 0.8594\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4546 - binary_accuracy: 0.8750\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.3807 - binary_accuracy: 0.8633\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5600 - binary_accuracy: 0.8828\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.3501 - binary_accuracy: 0.8789\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 1s 4ms/step - loss: 1.7693 - binary_accuracy: 0.6016\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6880 - binary_accuracy: 0.6680\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7459 - binary_accuracy: 0.7305\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6465 - binary_accuracy: 0.7246\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6226 - binary_accuracy: 0.7363\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6298 - binary_accuracy: 0.7207\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6858 - binary_accuracy: 0.7148\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5794 - binary_accuracy: 0.7559\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5592 - binary_accuracy: 0.7852\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6293 - binary_accuracy: 0.7559\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6007 - binary_accuracy: 0.7676\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4978 - binary_accuracy: 0.7773\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5346 - binary_accuracy: 0.7949\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4721 - binary_accuracy: 0.8066\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5366 - binary_accuracy: 0.7441\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5285 - binary_accuracy: 0.8008\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5051 - binary_accuracy: 0.7910\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5178 - binary_accuracy: 0.7637\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4779 - binary_accuracy: 0.7910\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5169 - binary_accuracy: 0.7910\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6360 - binary_accuracy: 0.7891\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5913 - binary_accuracy: 0.7578\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5411 - binary_accuracy: 0.7617\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5326 - binary_accuracy: 0.7812\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4781 - binary_accuracy: 0.8008\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4646 - binary_accuracy: 0.8066\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4416 - binary_accuracy: 0.8223\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4956 - binary_accuracy: 0.7969\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5024 - binary_accuracy: 0.8047\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4401 - binary_accuracy: 0.8242\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4713 - binary_accuracy: 0.7930\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4701 - binary_accuracy: 0.7988\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4301 - binary_accuracy: 0.8086\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4097 - binary_accuracy: 0.8359\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4753 - binary_accuracy: 0.8340\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4652 - binary_accuracy: 0.8066\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4323 - binary_accuracy: 0.8398\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4413 - binary_accuracy: 0.8457\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4605 - binary_accuracy: 0.8145\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4355 - binary_accuracy: 0.8359\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4422 - binary_accuracy: 0.8145\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4398 - binary_accuracy: 0.8359\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4247 - binary_accuracy: 0.8438\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4412 - binary_accuracy: 0.8418\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4084 - binary_accuracy: 0.8516\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4362 - binary_accuracy: 0.8320\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3808 - binary_accuracy: 0.8652\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4310 - binary_accuracy: 0.8691\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3502 - binary_accuracy: 0.8652\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3902 - binary_accuracy: 0.8730\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5397 - binary_accuracy: 0.8418\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5482 - binary_accuracy: 0.8516\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3875 - binary_accuracy: 0.8516\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4284 - binary_accuracy: 0.8594\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4384 - binary_accuracy: 0.8379\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4332 - binary_accuracy: 0.8633\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4595 - binary_accuracy: 0.8633\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4955 - binary_accuracy: 0.8418\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4415 - binary_accuracy: 0.8398\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4146 - binary_accuracy: 0.8828\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4886 - binary_accuracy: 0.8633\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4696 - binary_accuracy: 0.8438\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3924 - binary_accuracy: 0.8613\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4312 - binary_accuracy: 0.8457\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3823 - binary_accuracy: 0.8496\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4023 - binary_accuracy: 0.8672\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4290 - binary_accuracy: 0.8594\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4627 - binary_accuracy: 0.8770\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4906 - binary_accuracy: 0.8516\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4505 - binary_accuracy: 0.8652\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4977 - binary_accuracy: 0.8809\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5493 - binary_accuracy: 0.8555\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4670 - binary_accuracy: 0.8633\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4506 - binary_accuracy: 0.8613\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4079 - binary_accuracy: 0.8711\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3560 - binary_accuracy: 0.8711\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5329 - binary_accuracy: 0.8613\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5285 - binary_accuracy: 0.8594\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5517 - binary_accuracy: 0.8750\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5569 - binary_accuracy: 0.8398\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4967 - binary_accuracy: 0.8496\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4924 - binary_accuracy: 0.8672\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6228 - binary_accuracy: 0.8438\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4503 - binary_accuracy: 0.8633\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6509 - binary_accuracy: 0.8496\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5688 - binary_accuracy: 0.8613\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7789 - binary_accuracy: 0.8574\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6965 - binary_accuracy: 0.8594\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6305 - binary_accuracy: 0.8750\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7102 - binary_accuracy: 0.8516\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5670 - binary_accuracy: 0.8477\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4825 - binary_accuracy: 0.8672\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6038 - binary_accuracy: 0.8477\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7003 - binary_accuracy: 0.8594\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7414 - binary_accuracy: 0.8516\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5881 - binary_accuracy: 0.8652\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5165 - binary_accuracy: 0.8691\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4925 - binary_accuracy: 0.8730\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4303 - binary_accuracy: 0.8770\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6055 - binary_accuracy: 0.8711\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 1s 3ms/step - loss: 1.2945 - binary_accuracy: 0.6230\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5664 - binary_accuracy: 0.6738\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6332 - binary_accuracy: 0.7168\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.5660 - binary_accuracy: 0.7383\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5480 - binary_accuracy: 0.7480\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5854 - binary_accuracy: 0.7598\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6775 - binary_accuracy: 0.7695\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8255 - binary_accuracy: 0.8008\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9396 - binary_accuracy: 0.7441\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8411 - binary_accuracy: 0.7695\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8960 - binary_accuracy: 0.7930\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2569 - binary_accuracy: 0.7754\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8954 - binary_accuracy: 0.7852\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6688 - binary_accuracy: 0.7969\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6529 - binary_accuracy: 0.7930\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5830 - binary_accuracy: 0.8105\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8780 - binary_accuracy: 0.7988\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7168 - binary_accuracy: 0.8105\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7743 - binary_accuracy: 0.8066\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7752 - binary_accuracy: 0.7852\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8278 - binary_accuracy: 0.8125\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5443 - binary_accuracy: 0.8086\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4983 - binary_accuracy: 0.8086\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5482 - binary_accuracy: 0.8125\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6969 - binary_accuracy: 0.8242\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6964 - binary_accuracy: 0.8496\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8064 - binary_accuracy: 0.8203\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6827 - binary_accuracy: 0.8164\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4319 - binary_accuracy: 0.8359\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9269 - binary_accuracy: 0.8340\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8246 - binary_accuracy: 0.7988\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4161 - binary_accuracy: 0.8301\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8702 - binary_accuracy: 0.8340\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.0221 - binary_accuracy: 0.8359\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5829 - binary_accuracy: 0.8574\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7451 - binary_accuracy: 0.8398\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6389 - binary_accuracy: 0.8242\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6622 - binary_accuracy: 0.8398\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7594 - binary_accuracy: 0.8145\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5486 - binary_accuracy: 0.8594\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4753 - binary_accuracy: 0.8594\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9139 - binary_accuracy: 0.8633\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5912 - binary_accuracy: 0.8516\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9817 - binary_accuracy: 0.8457\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8490 - binary_accuracy: 0.8652\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7274 - binary_accuracy: 0.8652\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6422 - binary_accuracy: 0.8711\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.3977 - binary_accuracy: 0.8398\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9341 - binary_accuracy: 0.8711\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4247 - binary_accuracy: 0.8496\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.0915 - binary_accuracy: 0.8477\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.3320 - binary_accuracy: 0.8516\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7715 - binary_accuracy: 0.8535\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8181 - binary_accuracy: 0.8652\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8527 - binary_accuracy: 0.8789\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5902 - binary_accuracy: 0.8691\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.4284 - binary_accuracy: 0.8828\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.9805 - binary_accuracy: 0.8730\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.1404 - binary_accuracy: 0.8848\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2926 - binary_accuracy: 0.8672\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5492 - binary_accuracy: 0.8691\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4678 - binary_accuracy: 0.8730\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6552 - binary_accuracy: 0.8691\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6923 - binary_accuracy: 0.8828\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4635 - binary_accuracy: 0.8770\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.0694 - binary_accuracy: 0.8848\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9733 - binary_accuracy: 0.8770\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.3175 - binary_accuracy: 0.8809\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.1530 - binary_accuracy: 0.8828\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4223 - binary_accuracy: 0.8926\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3521 - binary_accuracy: 0.8945\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6658 - binary_accuracy: 0.8672\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.3196 - binary_accuracy: 0.8711\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8534 - binary_accuracy: 0.9023\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.0855 - binary_accuracy: 0.8887\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9512 - binary_accuracy: 0.8984\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7272 - binary_accuracy: 0.8750\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4248 - binary_accuracy: 0.8887\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7515 - binary_accuracy: 0.8789\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9606 - binary_accuracy: 0.8965\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4695 - binary_accuracy: 0.8848\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.4372 - binary_accuracy: 0.8867\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.2864 - binary_accuracy: 0.9043\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7807 - binary_accuracy: 0.8809\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7269 - binary_accuracy: 0.8945\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6033 - binary_accuracy: 0.8867\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4214 - binary_accuracy: 0.8730\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.2236 - binary_accuracy: 0.9043\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6128 - binary_accuracy: 0.8691\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.1696 - binary_accuracy: 0.8770\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8083 - binary_accuracy: 0.8867\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.9865 - binary_accuracy: 0.8711\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.0395 - binary_accuracy: 0.8770\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.0329 - binary_accuracy: 0.8770\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4981 - binary_accuracy: 0.8926\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6036 - binary_accuracy: 0.8906\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.3848 - binary_accuracy: 0.9062\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.7538 - binary_accuracy: 0.8965\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9910 - binary_accuracy: 0.8828\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.2527 - binary_accuracy: 0.8828\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 1s 3ms/step - loss: 1.0894 - binary_accuracy: 0.6074\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7771 - binary_accuracy: 0.5938\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.6427 - binary_accuracy: 0.5957\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6962 - binary_accuracy: 0.6074\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6674 - binary_accuracy: 0.6094\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6258 - binary_accuracy: 0.6035\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6493 - binary_accuracy: 0.6367\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6589 - binary_accuracy: 0.6094\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6985 - binary_accuracy: 0.5898\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7064 - binary_accuracy: 0.6152\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6359 - binary_accuracy: 0.5918\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6303 - binary_accuracy: 0.6465\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6170 - binary_accuracy: 0.6602\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6302 - binary_accuracy: 0.6582\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6498 - binary_accuracy: 0.6641\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6496 - binary_accuracy: 0.6445\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6438 - binary_accuracy: 0.6641\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6116 - binary_accuracy: 0.6895\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6040 - binary_accuracy: 0.6602\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5857 - binary_accuracy: 0.7012\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5590 - binary_accuracy: 0.6895\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5964 - binary_accuracy: 0.6777\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5602 - binary_accuracy: 0.6914\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5793 - binary_accuracy: 0.7344\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5334 - binary_accuracy: 0.7305\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5151 - binary_accuracy: 0.7441\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5347 - binary_accuracy: 0.7539\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5363 - binary_accuracy: 0.7344\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5607 - binary_accuracy: 0.7285\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4896 - binary_accuracy: 0.7676\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5234 - binary_accuracy: 0.7441\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5079 - binary_accuracy: 0.7656\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5457 - binary_accuracy: 0.7559\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5248 - binary_accuracy: 0.7559\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5652 - binary_accuracy: 0.7402\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4852 - binary_accuracy: 0.7656\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5199 - binary_accuracy: 0.7656\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4846 - binary_accuracy: 0.7754\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4925 - binary_accuracy: 0.7598\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5152 - binary_accuracy: 0.7695\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4571 - binary_accuracy: 0.7773\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5908 - binary_accuracy: 0.7656\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6036 - binary_accuracy: 0.7832\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4516 - binary_accuracy: 0.7930\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5176 - binary_accuracy: 0.7832\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7087 - binary_accuracy: 0.7559\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6409 - binary_accuracy: 0.8008\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5650 - binary_accuracy: 0.7480\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4864 - binary_accuracy: 0.7988\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4814 - binary_accuracy: 0.7930\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5086 - binary_accuracy: 0.7910\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4349 - binary_accuracy: 0.8086\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4396 - binary_accuracy: 0.8086\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5978 - binary_accuracy: 0.7598\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5023 - binary_accuracy: 0.7754\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4526 - binary_accuracy: 0.8027\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6858 - binary_accuracy: 0.7969\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5011 - binary_accuracy: 0.7930\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5307 - binary_accuracy: 0.8223\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5065 - binary_accuracy: 0.8105\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4561 - binary_accuracy: 0.8203\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7000 - binary_accuracy: 0.8066\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4709 - binary_accuracy: 0.7891\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4876 - binary_accuracy: 0.8008\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4930 - binary_accuracy: 0.7871\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4498 - binary_accuracy: 0.7969\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4616 - binary_accuracy: 0.8105\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4699 - binary_accuracy: 0.8086\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6205 - binary_accuracy: 0.7949\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4170 - binary_accuracy: 0.8242\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4635 - binary_accuracy: 0.8145\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4678 - binary_accuracy: 0.7891\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4664 - binary_accuracy: 0.7949\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4443 - binary_accuracy: 0.8203\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4741 - binary_accuracy: 0.8145\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5126 - binary_accuracy: 0.8340\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4422 - binary_accuracy: 0.8145\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7940 - binary_accuracy: 0.8242\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4929 - binary_accuracy: 0.8203\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4248 - binary_accuracy: 0.8164\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5246 - binary_accuracy: 0.7852\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4320 - binary_accuracy: 0.8242\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4372 - binary_accuracy: 0.8262\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7726 - binary_accuracy: 0.8145\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4126 - binary_accuracy: 0.8379\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4839 - binary_accuracy: 0.7988\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4352 - binary_accuracy: 0.8379\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5357 - binary_accuracy: 0.8418\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4577 - binary_accuracy: 0.8066\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.5467 - binary_accuracy: 0.8242\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4963 - binary_accuracy: 0.7793\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4303 - binary_accuracy: 0.8281\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6398 - binary_accuracy: 0.8320\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.0921 - binary_accuracy: 0.8008\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5850 - binary_accuracy: 0.8223\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4647 - binary_accuracy: 0.8242\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3723 - binary_accuracy: 0.8555\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4229 - binary_accuracy: 0.8359\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6399 - binary_accuracy: 0.8398\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4651 - binary_accuracy: 0.8262\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f704c599280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 1s 2ms/step - loss: 3.3027 - binary_accuracy: 0.5762\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7707 - binary_accuracy: 0.6719\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7619 - binary_accuracy: 0.6582\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6813 - binary_accuracy: 0.6523\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6287 - binary_accuracy: 0.7012\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5651 - binary_accuracy: 0.7207\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6232 - binary_accuracy: 0.7168\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6398 - binary_accuracy: 0.7109\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5349 - binary_accuracy: 0.7637\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5664 - binary_accuracy: 0.7617\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6804 - binary_accuracy: 0.7090\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5727 - binary_accuracy: 0.7148\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6255 - binary_accuracy: 0.7500\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7653 - binary_accuracy: 0.7559\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5822 - binary_accuracy: 0.7656\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6288 - binary_accuracy: 0.7852\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6630 - binary_accuracy: 0.7734\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7297 - binary_accuracy: 0.7402\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7012 - binary_accuracy: 0.7832\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5508 - binary_accuracy: 0.8066\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8694 - binary_accuracy: 0.7617\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6811 - binary_accuracy: 0.7852\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5689 - binary_accuracy: 0.8047\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6646 - binary_accuracy: 0.8184\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6450 - binary_accuracy: 0.8066\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6149 - binary_accuracy: 0.7949\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6469 - binary_accuracy: 0.8184\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5835 - binary_accuracy: 0.7930\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6181 - binary_accuracy: 0.8105\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9694 - binary_accuracy: 0.7871\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7789 - binary_accuracy: 0.7812\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7383 - binary_accuracy: 0.8125\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6283 - binary_accuracy: 0.8262\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.9007 - binary_accuracy: 0.8086\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6521 - binary_accuracy: 0.8105\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5064 - binary_accuracy: 0.8027\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9254 - binary_accuracy: 0.8223\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7500 - binary_accuracy: 0.8223\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.1047 - binary_accuracy: 0.8281\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5360 - binary_accuracy: 0.8555\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5181 - binary_accuracy: 0.8359\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.3265 - binary_accuracy: 0.8242\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6032 - binary_accuracy: 0.8398\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4040 - binary_accuracy: 0.8555\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7690 - binary_accuracy: 0.8281\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5592 - binary_accuracy: 0.8535\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4983 - binary_accuracy: 0.8535\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9960 - binary_accuracy: 0.8477\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4678 - binary_accuracy: 0.8613\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5854 - binary_accuracy: 0.8535\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5491 - binary_accuracy: 0.8594\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4275 - binary_accuracy: 0.8770\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.1009 - binary_accuracy: 0.8574\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4125 - binary_accuracy: 0.8691\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5804 - binary_accuracy: 0.8496\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9955 - binary_accuracy: 0.8633\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6136 - binary_accuracy: 0.8574\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8092 - binary_accuracy: 0.8652\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.1155 - binary_accuracy: 0.8711\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4742 - binary_accuracy: 0.8672\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5002 - binary_accuracy: 0.8809\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5227 - binary_accuracy: 0.8555\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3924 - binary_accuracy: 0.8887\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8465 - binary_accuracy: 0.8848\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4775 - binary_accuracy: 0.8672\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.3476 - binary_accuracy: 0.8906\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4799 - binary_accuracy: 0.8848\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6095 - binary_accuracy: 0.8828\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3174 - binary_accuracy: 0.8926\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8329 - binary_accuracy: 0.8730\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6917 - binary_accuracy: 0.8848\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7823 - binary_accuracy: 0.8965\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.0800 - binary_accuracy: 0.8574\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8810 - binary_accuracy: 0.8809\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3414 - binary_accuracy: 0.8887\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.2452 - binary_accuracy: 0.8594\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.5501 - binary_accuracy: 0.8770\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7957 - binary_accuracy: 0.8652\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.8449 - binary_accuracy: 0.8594\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4257 - binary_accuracy: 0.8594\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4061 - binary_accuracy: 0.8730\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.0406 - binary_accuracy: 0.8770\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.7985 - binary_accuracy: 0.8633\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.1124 - binary_accuracy: 0.8477\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.4832 - binary_accuracy: 0.8789\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9369 - binary_accuracy: 0.8750\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.0974 - binary_accuracy: 0.8711\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4339 - binary_accuracy: 0.9023\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9008 - binary_accuracy: 0.8750\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4746 - binary_accuracy: 0.8770\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.6056 - binary_accuracy: 0.8633\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8747 - binary_accuracy: 0.8594\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8600 - binary_accuracy: 0.8613\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4724 - binary_accuracy: 0.8945\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8816 - binary_accuracy: 0.8867\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7249 - binary_accuracy: 0.8672\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.0951 - binary_accuracy: 0.8496\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.4319 - binary_accuracy: 0.8555\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3704 - binary_accuracy: 0.8867\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7924 - binary_accuracy: 0.8730\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f704c3fe9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 1s 2ms/step - loss: 0.9477 - binary_accuracy: 0.6055\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6419 - binary_accuracy: 0.6172\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6985 - binary_accuracy: 0.6465\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6060 - binary_accuracy: 0.6348\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6319 - binary_accuracy: 0.6875\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6844 - binary_accuracy: 0.7012\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6846 - binary_accuracy: 0.7090\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6860 - binary_accuracy: 0.6602\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6070 - binary_accuracy: 0.7207\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5773 - binary_accuracy: 0.7441\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6808 - binary_accuracy: 0.7539\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6499 - binary_accuracy: 0.7461\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7464 - binary_accuracy: 0.7324\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5551 - binary_accuracy: 0.7754\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8058 - binary_accuracy: 0.7480\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8780 - binary_accuracy: 0.7734\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6711 - binary_accuracy: 0.7539\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5840 - binary_accuracy: 0.7285\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.7109 - binary_accuracy: 0.7422\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.1467 - binary_accuracy: 0.7461\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9221 - binary_accuracy: 0.7930\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8236 - binary_accuracy: 0.7500\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7351 - binary_accuracy: 0.7891\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5108 - binary_accuracy: 0.7812\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9068 - binary_accuracy: 0.7539\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8018 - binary_accuracy: 0.7852\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5284 - binary_accuracy: 0.7969\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4724 - binary_accuracy: 0.8262\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8737 - binary_accuracy: 0.8105\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9019 - binary_accuracy: 0.8027\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7998 - binary_accuracy: 0.8086\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5629 - binary_accuracy: 0.8086\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4894 - binary_accuracy: 0.8516\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6667 - binary_accuracy: 0.7891\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8850 - binary_accuracy: 0.8340\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6712 - binary_accuracy: 0.8223\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7743 - binary_accuracy: 0.8262\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7010 - binary_accuracy: 0.8301\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.7204 - binary_accuracy: 0.8359\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.2165 - binary_accuracy: 0.7969\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.9028 - binary_accuracy: 0.8184\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8427 - binary_accuracy: 0.8125\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.4562 - binary_accuracy: 0.8301\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.0967 - binary_accuracy: 0.8262\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.2833 - binary_accuracy: 0.7949\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.1811 - binary_accuracy: 0.8066\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1975 - binary_accuracy: 0.8223\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.0575 - binary_accuracy: 0.8164\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7419 - binary_accuracy: 0.8066\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.0343 - binary_accuracy: 0.7891\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.0695 - binary_accuracy: 0.8047\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.4976 - binary_accuracy: 0.8027\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.4504 - binary_accuracy: 0.8086\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.5263 - binary_accuracy: 0.8066\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8697 - binary_accuracy: 0.7969\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.0871 - binary_accuracy: 0.8086\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.1256 - binary_accuracy: 0.8027\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6077 - binary_accuracy: 0.8320\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5831 - binary_accuracy: 0.8145\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7003 - binary_accuracy: 0.7969\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9039 - binary_accuracy: 0.8262\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8719 - binary_accuracy: 0.8301\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8763 - binary_accuracy: 0.8125\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7979 - binary_accuracy: 0.7832\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.1175 - binary_accuracy: 0.8066\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8588 - binary_accuracy: 0.8379\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7667 - binary_accuracy: 0.7988\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6260 - binary_accuracy: 0.7930\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7304 - binary_accuracy: 0.8262\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9807 - binary_accuracy: 0.7969\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.1618 - binary_accuracy: 0.7930\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.7562 - binary_accuracy: 0.8320\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8870 - binary_accuracy: 0.8008\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8347 - binary_accuracy: 0.7988\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.9152 - binary_accuracy: 0.8262\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9059 - binary_accuracy: 0.8301\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7850 - binary_accuracy: 0.7930\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.2381 - binary_accuracy: 0.8008\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7228 - binary_accuracy: 0.7695\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5272 - binary_accuracy: 0.7988\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7737 - binary_accuracy: 0.8320\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.1534 - binary_accuracy: 0.8145\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8309 - binary_accuracy: 0.7871\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6031 - binary_accuracy: 0.8164\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7703 - binary_accuracy: 0.8223\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5654 - binary_accuracy: 0.8184\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7905 - binary_accuracy: 0.8086\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5373 - binary_accuracy: 0.8066\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6377 - binary_accuracy: 0.8086\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8559 - binary_accuracy: 0.8008\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.0608 - binary_accuracy: 0.8066\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9928 - binary_accuracy: 0.8145\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6324 - binary_accuracy: 0.7988\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9079 - binary_accuracy: 0.7871\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 1.6220 - binary_accuracy: 0.7891\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9123 - binary_accuracy: 0.8066\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8422 - binary_accuracy: 0.8066\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.1198 - binary_accuracy: 0.7852\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 2.2678 - binary_accuracy: 0.7793\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.8987 - binary_accuracy: 0.8086\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 1s 3ms/step - loss: 2.2591 - binary_accuracy: 0.5078\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.7958 - binary_accuracy: 0.5898\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6009 - binary_accuracy: 0.6426\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5897 - binary_accuracy: 0.6582\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6227 - binary_accuracy: 0.6406\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5950 - binary_accuracy: 0.6543\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6604 - binary_accuracy: 0.6582\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5594 - binary_accuracy: 0.7129\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6471 - binary_accuracy: 0.6836\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5887 - binary_accuracy: 0.6992\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6342 - binary_accuracy: 0.7324\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5702 - binary_accuracy: 0.6875\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5731 - binary_accuracy: 0.7090\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5808 - binary_accuracy: 0.7148\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6232 - binary_accuracy: 0.7148\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6217 - binary_accuracy: 0.7500\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5995 - binary_accuracy: 0.7324\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6054 - binary_accuracy: 0.7598\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5593 - binary_accuracy: 0.7617\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5588 - binary_accuracy: 0.7422\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5364 - binary_accuracy: 0.7559\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5997 - binary_accuracy: 0.7734\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4838 - binary_accuracy: 0.7852\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5579 - binary_accuracy: 0.7891\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5122 - binary_accuracy: 0.7988\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5178 - binary_accuracy: 0.7910\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4987 - binary_accuracy: 0.8027\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5144 - binary_accuracy: 0.7773\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4564 - binary_accuracy: 0.8203\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4713 - binary_accuracy: 0.8125\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4988 - binary_accuracy: 0.8066\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4495 - binary_accuracy: 0.8203\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4828 - binary_accuracy: 0.8340\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4612 - binary_accuracy: 0.8223\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5144 - binary_accuracy: 0.8125\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5450 - binary_accuracy: 0.8047\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4815 - binary_accuracy: 0.8418\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5600 - binary_accuracy: 0.8125\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5101 - binary_accuracy: 0.8047\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.4668 - binary_accuracy: 0.8203\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.4711 - binary_accuracy: 0.8340\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.4852 - binary_accuracy: 0.8223\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.5518 - binary_accuracy: 0.8340\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.6523 - binary_accuracy: 0.8281\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.4418 - binary_accuracy: 0.8418\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5279 - binary_accuracy: 0.8340\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.4645 - binary_accuracy: 0.8418\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5011 - binary_accuracy: 0.8203\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 0.4754 - binary_accuracy: 0.8184\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.4752 - binary_accuracy: 0.8262\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.4680 - binary_accuracy: 0.8301\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 0.6174 - binary_accuracy: 0.8516\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 27ms/step - loss: 0.4701 - binary_accuracy: 0.8359\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.4546 - binary_accuracy: 0.8379\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.5289 - binary_accuracy: 0.8223\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.6622 - binary_accuracy: 0.8555\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.5112 - binary_accuracy: 0.8477\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.9937 - binary_accuracy: 0.8359\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.6261 - binary_accuracy: 0.8223\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.0027 - binary_accuracy: 0.8086\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.4461 - binary_accuracy: 0.8164\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.6237 - binary_accuracy: 0.8340\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.4283 - binary_accuracy: 0.8633\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.6212 - binary_accuracy: 0.8594\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.9519 - binary_accuracy: 0.8457\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7502 - binary_accuracy: 0.8379\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.6481 - binary_accuracy: 0.8262\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 0.5309 - binary_accuracy: 0.8242\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 0.9715 - binary_accuracy: 0.8438\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.6712 - binary_accuracy: 0.8633\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.6318 - binary_accuracy: 0.8320\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.8407 - binary_accuracy: 0.8555\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.8609 - binary_accuracy: 0.8457\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.5080 - binary_accuracy: 0.8496\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.7440 - binary_accuracy: 0.8477\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.8827 - binary_accuracy: 0.8281\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.6613 - binary_accuracy: 0.8594\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.6946 - binary_accuracy: 0.8477\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.9278 - binary_accuracy: 0.8457\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.7792 - binary_accuracy: 0.8496\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.5307 - binary_accuracy: 0.8242\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.7862 - binary_accuracy: 0.8555\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.6537 - binary_accuracy: 0.8418\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.4905 - binary_accuracy: 0.8457\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.5368 - binary_accuracy: 0.8496\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.6166 - binary_accuracy: 0.8418\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4822 - binary_accuracy: 0.8496\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.1939 - binary_accuracy: 0.8555\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.8682 - binary_accuracy: 0.8418\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 1.1219 - binary_accuracy: 0.8438\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 0.8075 - binary_accuracy: 0.8398\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5862 - binary_accuracy: 0.8730\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.1521 - binary_accuracy: 0.8496\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.6285 - binary_accuracy: 0.8672\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.0671 - binary_accuracy: 0.8613\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.4553 - binary_accuracy: 0.8477\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8084 - binary_accuracy: 0.8477\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5371 - binary_accuracy: 0.8672\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4475 - binary_accuracy: 0.8633\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5318 - binary_accuracy: 0.8457\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 1s 3ms/step - loss: 1.1547 - binary_accuracy: 0.5195\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.7313 - binary_accuracy: 0.5723\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.5742 - binary_accuracy: 0.6641\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 0.5745 - binary_accuracy: 0.6602\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.5705 - binary_accuracy: 0.6699\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.5372 - binary_accuracy: 0.7031\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 0.4782 - binary_accuracy: 0.7969\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 0.5074 - binary_accuracy: 0.7578\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 0.5467 - binary_accuracy: 0.7754\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 0.4642 - binary_accuracy: 0.8066\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 0.6160 - binary_accuracy: 0.7715\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 0.5320 - binary_accuracy: 0.8203\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.5398 - binary_accuracy: 0.8008\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.4318 - binary_accuracy: 0.8105\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.4609 - binary_accuracy: 0.8086\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5103 - binary_accuracy: 0.8203\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.6821 - binary_accuracy: 0.8262\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.7481 - binary_accuracy: 0.8281\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.6930 - binary_accuracy: 0.7969\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.4488 - binary_accuracy: 0.8086\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.5175 - binary_accuracy: 0.8047\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.5657 - binary_accuracy: 0.8379\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 0.6670 - binary_accuracy: 0.8281\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 0.7079 - binary_accuracy: 0.8320\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.9768 - binary_accuracy: 0.8223\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.6197 - binary_accuracy: 0.8379\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.5035 - binary_accuracy: 0.8574\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 2s 35ms/step - loss: 0.6526 - binary_accuracy: 0.8711\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.5361 - binary_accuracy: 0.8652\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.4855 - binary_accuracy: 0.8770\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5393 - binary_accuracy: 0.8535\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 2s 28ms/step - loss: 0.4250 - binary_accuracy: 0.8438\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 0.3550 - binary_accuracy: 0.8652\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.4890 - binary_accuracy: 0.8828\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 0.5227 - binary_accuracy: 0.8633\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.5155 - binary_accuracy: 0.8711\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.6726 - binary_accuracy: 0.8516\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3922 - binary_accuracy: 0.9004\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3818 - binary_accuracy: 0.8828\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 2s 40ms/step - loss: 0.4357 - binary_accuracy: 0.8887\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 0.3405 - binary_accuracy: 0.8906\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 0.8791 - binary_accuracy: 0.8613\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.4002 - binary_accuracy: 0.8613\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 0.6017 - binary_accuracy: 0.8711\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.9491 - binary_accuracy: 0.8613\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 1.6125 - binary_accuracy: 0.8711\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.5877 - binary_accuracy: 0.8848\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.7315 - binary_accuracy: 0.8711\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.4147 - binary_accuracy: 0.8750\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.6586 - binary_accuracy: 0.8730\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.5073 - binary_accuracy: 0.8750\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.5811 - binary_accuracy: 0.8691\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 1.8779 - binary_accuracy: 0.8867\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 1s 29ms/step - loss: 2.0175 - binary_accuracy: 0.8594\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 1.1919 - binary_accuracy: 0.8555\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 0.5555 - binary_accuracy: 0.8789\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 2s 38ms/step - loss: 0.4057 - binary_accuracy: 0.8887\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.4878 - binary_accuracy: 0.8848\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.9765 - binary_accuracy: 0.8809\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 1.5306 - binary_accuracy: 0.8750\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.8966 - binary_accuracy: 0.8672\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.8973 - binary_accuracy: 0.8711\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 0.4921 - binary_accuracy: 0.8848\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 0.5912 - binary_accuracy: 0.8730\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 0.3645 - binary_accuracy: 0.8867\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 1.4253 - binary_accuracy: 0.9004\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 2s 35ms/step - loss: 0.3941 - binary_accuracy: 0.8652\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 0.8575 - binary_accuracy: 0.9023\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 0.3679 - binary_accuracy: 0.8594\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.3711 - binary_accuracy: 0.8633\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 0.5361 - binary_accuracy: 0.8750\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 1.0785 - binary_accuracy: 0.8652\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 1.0773 - binary_accuracy: 0.8848\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 1.0359 - binary_accuracy: 0.8828\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.3523 - binary_accuracy: 0.8945\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.4097 - binary_accuracy: 0.8926\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 0.3324 - binary_accuracy: 0.9004\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 2.2606 - binary_accuracy: 0.8711\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 2s 40ms/step - loss: 1.4909 - binary_accuracy: 0.8691\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.8775 - binary_accuracy: 0.8828\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.8355 - binary_accuracy: 0.8711\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 0.8000 - binary_accuracy: 0.9004\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 1.3508 - binary_accuracy: 0.8965\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 1.5048 - binary_accuracy: 0.8750\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.9184 - binary_accuracy: 0.8457\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 1.4185 - binary_accuracy: 0.8691\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.7793 - binary_accuracy: 0.8828\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.8276 - binary_accuracy: 0.8809\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.5148 - binary_accuracy: 0.8945\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 1.3098 - binary_accuracy: 0.8926\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 0.3457 - binary_accuracy: 0.8828\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 0.6297 - binary_accuracy: 0.8789\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 1.4240 - binary_accuracy: 0.8945\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 1.5160 - binary_accuracy: 0.8730\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.3158 - binary_accuracy: 0.8691\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.0759 - binary_accuracy: 0.8789\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 1.0898 - binary_accuracy: 0.8770\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 0.7523 - binary_accuracy: 0.8926\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 0.9571 - binary_accuracy: 0.8828\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.1241 - binary_accuracy: 0.8945\n",
      "2/2 [==============================] - 1s 15ms/step\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 5s 22ms/step - loss: 1.8184 - binary_accuracy: 0.5984\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.7361 - binary_accuracy: 0.6608\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 2s 28ms/step - loss: 0.6186 - binary_accuracy: 0.6920\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.5336 - binary_accuracy: 0.7427\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.6556 - binary_accuracy: 0.7096\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.5127 - binary_accuracy: 0.7524\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.5803 - binary_accuracy: 0.7700\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.5370 - binary_accuracy: 0.7739\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 0.5447 - binary_accuracy: 0.7641\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 0.5577 - binary_accuracy: 0.7583\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.5936 - binary_accuracy: 0.7602\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 0.5703 - binary_accuracy: 0.7622\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5443 - binary_accuracy: 0.7797\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 0.5124 - binary_accuracy: 0.7895\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 0.5020 - binary_accuracy: 0.8031\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.5641 - binary_accuracy: 0.7973\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 0.5571 - binary_accuracy: 0.7856\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 0.4763 - binary_accuracy: 0.7758\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 0.4870 - binary_accuracy: 0.7934\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 0.5039 - binary_accuracy: 0.8051\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.4878 - binary_accuracy: 0.7953\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 0.5075 - binary_accuracy: 0.7797\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.4934 - binary_accuracy: 0.7856\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.4401 - binary_accuracy: 0.8031\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.4987 - binary_accuracy: 0.7778\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.4766 - binary_accuracy: 0.8090\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 0.4845 - binary_accuracy: 0.7992\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.4482 - binary_accuracy: 0.8285\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 0.4579 - binary_accuracy: 0.8090\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 0.5110 - binary_accuracy: 0.8031\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.4456 - binary_accuracy: 0.8246\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 0.4993 - binary_accuracy: 0.7973\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 0.4666 - binary_accuracy: 0.8168\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 0.4369 - binary_accuracy: 0.8148\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.5165 - binary_accuracy: 0.8363\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.4632 - binary_accuracy: 0.8148\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 0.4472 - binary_accuracy: 0.8265\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 0.4863 - binary_accuracy: 0.8304\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.4435 - binary_accuracy: 0.8265\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 0.4719 - binary_accuracy: 0.8402\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 0.4285 - binary_accuracy: 0.8402\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3933 - binary_accuracy: 0.8480\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.4638 - binary_accuracy: 0.8148\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.4225 - binary_accuracy: 0.8519\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 0.6276 - binary_accuracy: 0.8480\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 0.4932 - binary_accuracy: 0.8304\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 1s 25ms/step - loss: 0.4646 - binary_accuracy: 0.8499\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4830 - binary_accuracy: 0.8343\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 0.4685 - binary_accuracy: 0.8499\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.5074 - binary_accuracy: 0.8538\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.4027 - binary_accuracy: 0.8577\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 1s 18ms/step - loss: 0.3886 - binary_accuracy: 0.8480\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 1.1585 - binary_accuracy: 0.8519\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 1s 24ms/step - loss: 0.5163 - binary_accuracy: 0.8616\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 0.4021 - binary_accuracy: 0.8441\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 1s 26ms/step - loss: 0.8678 - binary_accuracy: 0.8538\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 0.5451 - binary_accuracy: 0.8616\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.3747 - binary_accuracy: 0.8616\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 0.7036 - binary_accuracy: 0.8441\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 1s 29ms/step - loss: 1.0339 - binary_accuracy: 0.8460\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.9204 - binary_accuracy: 0.8577\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 1s 27ms/step - loss: 0.8871 - binary_accuracy: 0.8499\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 1s 28ms/step - loss: 0.6440 - binary_accuracy: 0.8713\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 1.0347 - binary_accuracy: 0.8285\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 1.4116 - binary_accuracy: 0.8226\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 1.1327 - binary_accuracy: 0.8694\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 1s 21ms/step - loss: 1.0743 - binary_accuracy: 0.8694\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 1.5436 - binary_accuracy: 0.8577\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.9741 - binary_accuracy: 0.8382\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.0395 - binary_accuracy: 0.8441\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 1.4004 - binary_accuracy: 0.8441\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.7203 - binary_accuracy: 0.8460\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 1.5827 - binary_accuracy: 0.8460\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.4114 - binary_accuracy: 0.8402\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.0335 - binary_accuracy: 0.8733\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.2079 - binary_accuracy: 0.8733\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 1.2151 - binary_accuracy: 0.8674\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.8221 - binary_accuracy: 0.8635\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 4ms/step - loss: 0.9107 - binary_accuracy: 0.8655\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.7426 - binary_accuracy: 0.8499\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 1.8111 - binary_accuracy: 0.8460\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.7202 - binary_accuracy: 0.8616\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.8383 - binary_accuracy: 0.8791\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 1s 19ms/step - loss: 1.2151 - binary_accuracy: 0.8811\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.9679 - binary_accuracy: 0.8382\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.0347 - binary_accuracy: 0.8713\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 3.3539 - binary_accuracy: 0.8596\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9970 - binary_accuracy: 0.8519\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0195 - binary_accuracy: 0.8519\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.9278 - binary_accuracy: 0.8733\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1224 - binary_accuracy: 0.8577\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.2754 - binary_accuracy: 0.8596\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.6735 - binary_accuracy: 0.8538\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2261 - binary_accuracy: 0.8694\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6427 - binary_accuracy: 0.8460\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.5241 - binary_accuracy: 0.8499\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.6605 - binary_accuracy: 0.8674\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.4197 - binary_accuracy: 0.8655\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.8752 - binary_accuracy: 0.8538\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.9811 - binary_accuracy: 0.8499\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "accuracies = cross_val_score(estimator=classifier, X=data, y=classes, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01049144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31877071",
   "metadata": {},
   "source": [
    "### Validating model accuracy\n",
    "\n",
    "A high standard deviation value indicates that the neural network is suffering from overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f1934f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 accuracy: 84.21%\n",
      "Round 2 accuracy: 82.46%\n",
      "Round 3 accuracy: 91.23%\n",
      "Round 4 accuracy: 85.96%\n",
      "Round 5 accuracy: 85.96%\n",
      "Round 6 accuracy: 96.49%\n",
      "Round 7 accuracy: 94.74%\n",
      "Round 8 accuracy: 94.74%\n",
      "Round 9 accuracy: 85.96%\n",
      "Round 10 accuracy: 89.29%\n"
     ]
    }
   ],
   "source": [
    "for index, accuracy in enumerate(accuracies):\n",
    "    print(f'Round {index + 1} accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96887be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5992d34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy average: 89.10%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy average: {accuracies.mean() * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53160afa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9863985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of accuracies: 4.69%\n"
     ]
    }
   ],
   "source": [
    "print(f'Standard deviation of accuracies: {accuracies.std() * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebdc1de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
